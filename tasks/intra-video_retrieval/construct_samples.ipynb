{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "segments = json.load(open('../../data/annotation.json'))\n",
    "animations = json.load(open('../../data/steps.json'))\n",
    "splits = json.load(open('../split.json'))\n",
    "train_set = splits['train']\n",
    "val_set = splits['val']\n",
    "test_set = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_samples(L1, L2, M):\n",
    "    samples = []\n",
    "    st = L1 // 2 + 1\n",
    "    for i in range(M):\n",
    "        m = st + int((L1 - st) * i / M)\n",
    "        try:\n",
    "            l = random.randint(max(1, 2*m-L1-L2+1), min(m-1, 2*m-L1))\n",
    "        except:\n",
    "            print(L1, L2, m)\n",
    "        r = m + (m - l)\n",
    "        samples.append((m, l, r))\n",
    "    return samples\n",
    "\n",
    "def construct_(segments, n_samples):\n",
    "    n_samples_tmp = n_samples\n",
    "    data = []\n",
    "    candidates = []\n",
    "    for i in range(len(segments) - 1):\n",
    "        if segments[i]['label'] > -1 and segments[i+1]['label'] > -1:\n",
    "            candidates.append(i)\n",
    "\n",
    "    n_samples_ = [0] * len(candidates)\n",
    "    while n_samples > 0:\n",
    "        for i in range(len(candidates)):\n",
    "            if n_samples > 0:\n",
    "                if segments[candidates[i]]['label'] == 0 or segments[candidates[i]+1]['label'] == 0:\n",
    "                    # There are too many irrelevant segments, so we need to draw samples from them less\n",
    "                    if random.randint(1, 100) == 1:\n",
    "                        n_samples_[i] += 1\n",
    "                        n_samples -= 1        \n",
    "                else:\n",
    "                    n_samples_[i] += 1\n",
    "                    n_samples -= 1\n",
    "    for i, M  in zip(candidates, n_samples_):\n",
    "        hf = M // 2\n",
    "\n",
    "        # Half samples with the query timestamp in the former segment\n",
    "        samples = get_samples(segments[i]['frame_end'] - segments[i]['frame_start'], segments[i+1]['frame_end'] - segments[i+1]['frame_start'], hf)\n",
    "        for m, l, r in samples:\n",
    "            data.append({\n",
    "                'query_frame_index': segments[i]['frame_start'] + m,\n",
    "                'candidates': [\n",
    "                    segments[i]['frame_start'] + l,\n",
    "                    segments[i]['frame_start'] + r\n",
    "                ]\n",
    "            })\n",
    "        \n",
    "        # Half samples with the query timestamp in the latter segment\n",
    "        samples = get_samples(segments[i+1]['frame_end'] - segments[i+1]['frame_start'], segments[i]['frame_end'] - segments[i]['frame_start'], M - hf)\n",
    "        L = segments[i+1]['frame_end'] - segments[i]['frame_start'] - 1\n",
    "        for m, l, r in samples:\n",
    "            data.append({\n",
    "                'query_frame_index': segments[i]['frame_start'] + L - m,\n",
    "                'candidates': [\n",
    "                    segments[i]['frame_start'] + L - l,\n",
    "                    segments[i]['frame_start'] + L - r\n",
    "                ]\n",
    "            })\n",
    "    for i in range(len(data)):\n",
    "        label = random.randint(0, 1)\n",
    "        if label == 1:\n",
    "            cans = [data[i]['candidates'][1], data[i]['candidates'][0]]\n",
    "        else:\n",
    "            cans = data[i]['candidates']\n",
    "        data[i]['candidate_frame_indices'] = cans\n",
    "        data[i].pop('candidates')\n",
    "        data[i]['label'] = label\n",
    "        data[i]['id'] = i\n",
    "    assert len(data) == n_samples_tmp\n",
    "    return data\n",
    "\n",
    "def construct(segments, dates, n_samples):\n",
    "    '''\n",
    "        Construct `n_samples` samples from each video listed in `dates`\n",
    "    '''\n",
    "    data = {}\n",
    "    for date in dates:\n",
    "        print('Processing:', date)\n",
    "        data[date] = construct_(segments[date], n_samples)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 01152020\n",
      "Processing: 01252020\n",
      "Processing: 01272021\n",
      "Processing: 02012021\n",
      "Processing: 03232022\n",
      "Processing: 06162021\n",
      "Processing: 10062019\n",
      "Processing: 11222019\n",
      "Processing: 12022021\n",
      "Processing: 12032022\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#             Warning                #\n",
    "# As randomness is involved, please  #\n",
    "# modify the output file name before #\n",
    "# running this code. Otherwise, it   #\n",
    "# will overwrite the training set.   # \n",
    "######################################\n",
    "\n",
    "# # Construct training set\n",
    "# data = construct(segments, train_set, 2000)\n",
    "# with open('train.json', 'w') as f:\n",
    "#     f.write(json.dumps(data, indent=4))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 03152022\n",
      "Processing: 11152022\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#             Warning               #\n",
    "# As randomness is involved, please #\n",
    "# don't run this to overwrite the   #\n",
    "# original validation set.          #\n",
    "#####################################\n",
    "\n",
    "# # Construct validation set\n",
    "# data = construct(segments, val_set, 2000)\n",
    "# with open('val.json', 'w') as f:\n",
    "#     f.write(json.dumps(data, indent=4))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 02282021\n",
      "Processing: 06092023\n",
      "Processing: 06262020\n",
      "Processing: 09122021\n",
      "Processing: 11152019\n",
      "Processing: 12022019\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#             Warning               #\n",
    "# As randomness is involved, please #\n",
    "# don't run this to overwrite the   #\n",
    "# original test set.                #\n",
    "#####################################\n",
    "\n",
    "# # Construct test set\n",
    "# data = construct(segments, test_set, 2000)\n",
    "# with open('test.json', 'w') as f:\n",
    "#     f.write(json.dumps(data, indent=4))\n",
    "#     f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
